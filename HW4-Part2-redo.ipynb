{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = {'Brush_teeth':0,\n",
    "            'Climb_stairs': 1,\n",
    "            'Comb_hair':2, \n",
    "            'Descend_stairs':3,\n",
    "            'Drink_glass':4, \n",
    "            'Eat_meat':5,\n",
    "            'Eat_soup':6,\n",
    "            'Getup_bed':7,\n",
    "            'Liedown_bed':8,\n",
    "            'Pour_water':9,\n",
    "            'Sitdown_chair':10,\n",
    "            'Standup_chair':11,\n",
    "            'Use_telephone':12, \n",
    "            'Walk':13\n",
    "            }\n",
    "\n",
    "X_files = [None]*len(activities)\n",
    "X_train_files = [None]*len(activities)\n",
    "X_test_files = [None]*len(activities)\n",
    "\n",
    "X_train_all = pd.DataFrame()\n",
    "X_train = [None]*len(activities)\n",
    "X_test = [None]*len(activities)\n",
    "\n",
    "chunk_size = 32\n",
    "k = 480\n",
    "\n",
    "def loadDataList():\n",
    "    global X_files, activities\n",
    "    for a in activities:\n",
    "        f_list = glob.glob(\"./HMP_Dataset/\" + a + \"/*.txt\")\n",
    "        X_files[activities[a]] = f_list\n",
    "        \n",
    "def splitTrainTest():\n",
    "    global X_train_files, X_test_files\n",
    "    for i, item in enumerate(X_files):\n",
    "        # not using y_train, ytest\n",
    "        X_train_files[i], X_test_files[i], y_train, y_test = train_test_split(X_files[i], [i]*len(X_files[i]), test_size=0.2, random_state=10)\n",
    "\n",
    "def getChunkedVectors(f):\n",
    "    global chunk_size\n",
    "    df_file = pd.read_table(f, sep=' ', header=None)\n",
    "    df = pd.DataFrame()\n",
    "    for l in range(0, len(df_file) - chunk_size, chunk_size):\n",
    "        chunk = df_file.iloc[l:l+32].values.flatten()\n",
    "        df = df.append([chunk])\n",
    "\n",
    "    return df\n",
    "\n",
    "def loadTrainingData():\n",
    "    global X_train_all\n",
    "    for cls, item in enumerate(X_train_files):\n",
    "        df = pd.DataFrame()\n",
    "        for f in X_train_files[cls]:\n",
    "            X_train_all = X_train_all.append(getChunkedVectors(f))            \n",
    "        \n",
    "loadDataList()\n",
    "splitTrainTest()\n",
    "loadTrainingData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook, distortion = kmeans(X_train_all.astype(float), 480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find histogram for training data\n",
    "\n",
    "VQ_Train = pd.DataFrame()\n",
    "VQ_Test = pd.DataFrame()\n",
    "\n",
    "def computeQuantizedVectors():\n",
    "    global VQ_Train, VQ_Test, codebook\n",
    "    for cls, item in enumerate(X_train_files):\n",
    "        for f in X_train_files[cls]:\n",
    "            df = getChunkedVectors(f)\n",
    "            code, dist = vq(df.astype('float'), codebook)\n",
    "            hist, ed = np.histogram(code, 480)\n",
    "            VQ_Train  = VQ_Train.append([np.append(hist, cls)])\n",
    "\n",
    "    for cls, item in enumerate(X_test_files):\n",
    "        for f in X_test_files[cls]:\n",
    "            df = getChunkedVectors(f)\n",
    "            code, dist = vq(df.astype('float'), codebook)\n",
    "            hist, ed = np.histogram(code, 480)\n",
    "            VQ_Test  = VQ_Test.append([np.append(hist, cls)])\n",
    "\n",
    "            \n",
    "computeQuantizedVectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(VQ_Train.drop(480, axis=1), VQ_Train[[480]].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17341040462427745"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted = clf.predict(VQ_Test.drop(480, axis=1))\n",
    "accuracy_score(VQ_Test[[480]].values.flatten(), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
